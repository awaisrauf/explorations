{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluating robustness to corruptions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM5ROP1p0LWEXs/CvZhMCdz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awaisrauf/explorations/blob/main/evaluating_robustness_to_corruptions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Robustness of Models against Common Corruptions\n",
        "\n",
        "- [x] To run common corruptions benchmark against cifar10 models.\n"
      ],
      "metadata": {
        "id": "GbYIzOIWD9lU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o-Y1A8ZisQ9"
      },
      "outputs": [],
      "source": [
        "# library \n",
        "!git clone https://github.com/tml-epfl/adv-training-corruptions.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd adv-training-corruptions/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGaNJOz2iv5O",
        "outputId": "e4f397c9-a9df-41a6-d73a-754428ce2da9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/adv-training-corruptions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install robustness\n",
        "!pip install torch==1.8.1 torchvision==0.9.1  # for robustness library, higher version are not compatiable"
      ],
      "metadata": {
        "id": "1tMH7j5mi-wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/RobustBench/robustbench.git\n",
        "!cd robustbench/\n",
        "!pip install ."
      ],
      "metadata": {
        "id": "ww_zgJQ1jFDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd adv-training-corruptions/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85p9fny4kRR5",
        "outputId": "1988093e-a745-4889-c2e8-68c894fc292a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/adv-training-corruptions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the eval_cifar10c is loading all the corruptions at the same time. This causes overuse of cpu and crashes the noteboo.\n",
        "# need to change it. May be one corruption at a time.\n",
        "\n",
        "!python eval_cifar10c.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0tYWuV3i4Ve",
        "outputId": "35449ee0-d6e9-4dca-8302-9feb0a6c178d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Clean accuracy:  0.1009\n",
            "Files already downloaded and verified\n",
            "shot_noise 1 0.1006\n",
            "motion_blur 1 0.1009\n",
            "snow 1 0.1015\n",
            "pixelate 1 0.1006\n",
            "gaussian_noise 1 0.1004\n",
            "defocus_blur 1 0.101\n",
            "brightness 1 0.1015\n",
            "fog 1 0.1007\n",
            "zoom_blur 1 0.1009\n",
            "frost 1 0.1039\n",
            "glass_blur 1 0.101\n",
            "impulse_noise 1 0.1008\n",
            "contrast 1 0.1014\n",
            "jpeg_compression 1 0.1009\n",
            "elastic_transform 1 0.1008\n",
            "Traceback (most recent call last):\n",
            "  File \"eval_cifar10c.py\", line 62, in <module>\n",
            "    main()\n",
            "  File \"eval_cifar10c.py\", line 53, in main\n",
            "    corr_res_last = corr_eval(x_corrs, y_corrs, model)\n",
            "  File \"eval_cifar10c.py\", line 18, in corr_eval\n",
            "    res[i-1, j] = clean_accuracy(model, x_corrs[i][j].cuda(), y_corrs[i][j].cuda())\n",
            "IndexError: list index out of range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v3Uf-aFto2nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Changes in the two files to make them less crash-prone"
      ],
      "metadata": {
        "id": "FtuA2RtMEtXH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`eval_cifar10c.py`\n",
        "```python\n",
        "\n",
        "# evaluating on all severties make the model crash\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import torch\n",
        "import models\n",
        "import pandas as pd\n",
        "import data\n",
        "\n",
        "from robustbench.data import load_cifar10\n",
        "from robustbench.utils import clean_accuracy\n",
        "\n",
        "\n",
        "def corr_eval(x_corrs, y_corrs, model):\n",
        "    model.eval()\n",
        "    res = np.zeros((5, 15))\n",
        "    for i in range(1, 6):\n",
        "        for j, c in enumerate(data.corruptions):\n",
        "            res[i-1, j] = clean_accuracy(model, x_corrs[i][j].cuda(), y_corrs[i][j].cuda())\n",
        "            print(c, i, res[i-1, j])\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def get_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--batch_size', default=128, type=int)\n",
        "    parser.add_argument('--data_dir', default='./data', type=str)\n",
        "    parser.add_argument('--checkpoint', default='', type=str)\n",
        "    parser.add_argument('--gpu', default=0, type=int)\n",
        "    parser.add_argument('--output', default='output11.csv', type=str)\n",
        "    parser.add_argument('--only_clean', action='store_true')\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "def main():\n",
        "    args = get_args()\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu)\n",
        "    x_clean, y_clean = load_cifar10(n_examples=10000, data_dir=args.data_dir)\n",
        "\n",
        "    model = models.PreActResNet18(n_cls=10, model_width=64, cifar_norm=True).cuda()\n",
        "    # model.load_state_dict(torch.load(args.checkpoint)['last'])\n",
        "    model.eval()\n",
        "\n",
        "    clean_acc = clean_accuracy(model, x_clean.cuda(), y_clean.cuda())\n",
        "    print(\"Clean accuracy: \", clean_acc)\n",
        "\n",
        "    if args.only_clean:\n",
        "        return\n",
        "    corrs = [1]\n",
        "    len_corrs = len(corrs)\n",
        "    x_corrs, y_corrs, _, _ = data.get_cifar10_numpy(corrs=corrs)\n",
        "    \n",
        "    corr_res_last = corr_eval(x_corrs, y_corrs, model)\n",
        "    corr_data_last = pd.DataFrame({i+1: corr_res_last[i, :] for i in range(0, len_corrs)}, index=data.corruptions)\n",
        "    corr_data_last.loc['average'] = {i+1: np.mean(corr_res_last, axis=1)[i] for i in range(0, len_corrs)}\n",
        "    corr_data_last['avg'] = corr_data_last[list(range(1,len_corrs))].mean(axis=1)\n",
        "    corr_data_last.to_csv(args.output)\n",
        "    print(corr_data_last)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "yLW1I8y0sINj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`data.py`\n",
        "\n",
        "```python\n",
        "import torch.utils.data as td\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import torch\n",
        "import tempfile\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from robustness.datasets import CIFAR, DATASETS, DataSet, CustomImageNet\n",
        "from robustbench.data import load_cifar10c, load_cifar10\n",
        "\n",
        "# Loaders for Imagenet100 were taken from https://github.com/cassidylaidlaw/perceptual-advex\n",
        "\n",
        "class ImageNet100(CustomImageNet):\n",
        "    def __init__(self, data_path, **kwargs):\n",
        "\n",
        "        super().__init__(\n",
        "            data_path=data_path,\n",
        "            custom_grouping=[[label] for label in range(0, 1000, 10)],\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "\n",
        "class ImageNet100A(CustomImageNet):\n",
        "    def __init__(self, data_path, **kwargs):\n",
        "        super().__init__(\n",
        "            data_path=data_path,\n",
        "            custom_grouping=[\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [8],\n",
        "                [],\n",
        "                [13],\n",
        "                [],\n",
        "                [15],\n",
        "                [],\n",
        "                [20],\n",
        "                [],\n",
        "                [28],\n",
        "                [],\n",
        "                [32],\n",
        "                [],\n",
        "                [36],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [53],\n",
        "                [],\n",
        "                [64],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [75],\n",
        "                [],\n",
        "                [83],\n",
        "                [86],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [94],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [104],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [125],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [150],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [159],\n",
        "                [],\n",
        "                [],\n",
        "                [167],\n",
        "                [],\n",
        "                [170],\n",
        "                [172],\n",
        "                [174],\n",
        "                [176],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [],\n",
        "                [194],\n",
        "                [],\n",
        "            ],\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "\n",
        "class ImageNet100C(CustomImageNet):\n",
        "    \"\"\"\n",
        "    ImageNet-C, but restricted to the ImageNet-100 classes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_path,\n",
        "        corruption_type: str = 'gaussian_noise',\n",
        "        severity: int = 1,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        # Need to create a temporary directory to act as the dataset because\n",
        "        # the robustness library expects a particular directory structure.\n",
        "        tmp_data_path = tempfile.mkdtemp()\n",
        "        os.symlink(os.path.join(data_path, corruption_type, str(severity)),\n",
        "                   os.path.join(tmp_data_path, 'test'))\n",
        "\n",
        "        super().__init__(\n",
        "            data_path=tmp_data_path,\n",
        "            custom_grouping=[[label] for label in range(0, 1000, 10)],\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "\n",
        "DATASETS['imagenet100'] = ImageNet100\n",
        "DATASETS['imagenet100a'] = ImageNet100A\n",
        "DATASETS['imagenet100c'] = ImageNet100C\n",
        "\n",
        "\n",
        "def get_loaders(dataset, n_ex, batch_size, train_set, shuffle, data_augm, n_train=-1, p_label_noise=0.0, drop_last=False):\n",
        "    dir_ = '../data/'\n",
        "    dataset_f = datasets_dict[dataset]\n",
        "    batch_size = n_ex if n_ex < batch_size and n_ex != -1 else batch_size\n",
        "    num_workers = 15\n",
        "\n",
        "    if dataset == 'imagenet100':\n",
        "        \n",
        "        if dataset == 'imagenet100':\n",
        "            imset = dataset_f(dir_ + '/imagenet/')\n",
        "\n",
        "            \n",
        "        if n_ex != -1:\n",
        "            train_loader, val_loader = imset.make_loaders(num_workers, batch_size, subset=n_ex)\n",
        "        else:\n",
        "            train_loader, val_loader = imset.make_loaders(num_workers, batch_size)\n",
        "        \n",
        "        \n",
        "        preprocess = transforms.Compose(\n",
        "            [transforms.ToTensor()])\n",
        "        \n",
        "        train_transform = transforms.Compose(\n",
        "            [transforms.RandomResizedCrop(224),\n",
        "             transforms.RandomHorizontalFlip(),\n",
        "             preprocess])\n",
        "        \n",
        "        test_transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            preprocess,\n",
        "        ])\n",
        "        train_dataset = train_loader.dataset\n",
        "        train_dataset.transform = train_transform\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            num_workers=num_workers, drop_last=drop_last, pin_memory=True)\n",
        "        val_dataset = val_loader.dataset\n",
        "        val_dataset.transform = test_transform\n",
        "        #print(val_dataset.transform)\n",
        "        val_loader = torch.utils.data.DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "        if train_set:\n",
        "            return train_loader\n",
        "        else:\n",
        "            return val_loader\n",
        "\n",
        "    data_augm_transforms = [transforms.RandomCrop(32, padding=4)]\n",
        "    if dataset not in ['mnist', 'svhn']:\n",
        "        #data_augm_transforms.append(transforms.RandomHorizontalFlip())\n",
        "        data_augm_transforms = [\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            #transforms.ColorJitter(.25,.25,.25),\n",
        "            #transforms.RandomRotation(2)\n",
        "        ]\n",
        "    transform_list = data_augm_transforms if data_augm else []\n",
        "    transform = transforms.Compose(transform_list + [transforms.ToTensor()])\n",
        "\n",
        "    if 'binary' in dataset:\n",
        "        cl1, cl2 = 1, 7  # cifar10: 1=auto, 7=horse\n",
        "    if train_set:\n",
        "        if dataset != 'svhn':\n",
        "            data = dataset_f(dir_, train=True, transform=transform, download=True)\n",
        "        else:\n",
        "            data = dataset_f(dir_, split='train', transform=transform, download=True)\n",
        "        n_ex = len(data) if n_ex == -1 else n_ex\n",
        "        n_cls = max(data.targets) + 1\n",
        "\n",
        "        if 'binary' in dataset:\n",
        "            data.targets = np.array(data.targets)\n",
        "            idx = (data.targets == cl1) + (data.targets == cl2)\n",
        "            data.data, data.targets = data.data[idx], data.targets[idx]\n",
        "            data.targets[data.targets == cl1], data.targets[data.targets == cl2] = 0, 1\n",
        "            # data.targets = list(data.targets)\n",
        "            n_ex = len(data.targets) if n_ex == -1 else n_ex\n",
        "            n_cls = 2\n",
        "        if '_gs' in dataset:\n",
        "            data.data = data.data.mean(3).astype(np.uint8)\n",
        "        if dataset == 'svhn':\n",
        "            data.targets = data.labels\n",
        "        data.data, data.targets = data.data[:n_ex], data.targets[:n_ex]\n",
        "\n",
        "        if n_train > 0:\n",
        "            indices = np.random.permutation(np.arange(n_ex))[:n_train]\n",
        "            data.data, data.targets = data.data[indices], data.targets[indices]\n",
        "            n_ex = n_train\n",
        "\n",
        "        data.label_noise = np.zeros(n_ex, dtype=bool)\n",
        "        if p_label_noise > 0.0:\n",
        "            # gen random indices\n",
        "            indices = np.random.permutation(np.arange(n_ex))[:int(n_ex*p_label_noise)]\n",
        "            for index in indices:\n",
        "                lst_classes = list(range(n_cls))\n",
        "                lst_classes.remove(data.targets[index].item())\n",
        "                data.targets[index] = np.random.choice(lst_classes)\n",
        "            data.label_noise[indices] = True\n",
        "\n",
        "        loader = torch.utils.data.DataLoader(dataset=data, batch_size=batch_size, shuffle=shuffle, pin_memory=True,\n",
        "                                             num_workers=num_workers, drop_last=drop_last)\n",
        "    else:\n",
        "        if dataset != 'svhn':\n",
        "            data = dataset_f(dir_, train=False, transform=transform, download=True)\n",
        "        else:\n",
        "            data = dataset_f(dir_, split='test', transform=transform, download=True)\n",
        "        n_ex = len(data) if n_ex == -1 else n_ex\n",
        "\n",
        "        if 'binary' in dataset:\n",
        "            data.targets = np.array(data.targets)\n",
        "            idx = (data.targets == cl1) + (data.targets == cl2)\n",
        "            data.data, data.targets = data.data[idx], data.targets[idx]\n",
        "            data.targets[data.targets == cl1], data.targets[data.targets == cl2] = 0, 1\n",
        "            data.targets = list(data.targets)  # to reduce memory consumption\n",
        "        if '_gs' in dataset:\n",
        "            data.data = data.data.mean(3).astype(np.uint8)\n",
        "        if dataset == 'svhn':\n",
        "            data.targets = data.labels\n",
        "        data.data, data.targets = data.data[:n_ex], data.targets[:n_ex]\n",
        "\n",
        "        data.label_noise = np.zeros(n_ex)\n",
        "        loader = torch.utils.data.DataLoader(dataset=data, batch_size=batch_size, shuffle=shuffle, pin_memory=False,\n",
        "                                             num_workers=2, drop_last=drop_last)\n",
        "    return loader\n",
        "\n",
        "\n",
        "def create_loader(x, y, ln, n_ex, batch_size, shuffle, drop_last):\n",
        "    if n_ex > 0:\n",
        "        x, y, ln = x[:n_ex], y[:n_ex], ln[:n_ex]\n",
        "    data = td.TensorDataset(x, y, ln)\n",
        "    loader = torch.utils.data.DataLoader(dataset=data, batch_size=batch_size, shuffle=shuffle, pin_memory=False,\n",
        "                                         num_workers=2, drop_last=drop_last)\n",
        "    return loader\n",
        "\n",
        "\n",
        "def get_xy_from_loader(loader, cuda=True):\n",
        "    tuples = [(x, y, ln) for (x, y, ln) in loader]\n",
        "    x_vals = torch.cat([x for (x, y, ln) in tuples])\n",
        "    y_vals = torch.cat([y for (x, y, ln) in tuples])\n",
        "    ln_vals = torch.cat([ln for (x, y, ln) in tuples])\n",
        "    if cuda:\n",
        "        x_vals, y_vals, ln_vals = x_vals.cuda(), y_vals.cuda(), ln_vals.cuda()\n",
        "    return x_vals, y_vals, ln_vals\n",
        "\n",
        "\n",
        "def get_cifar10_numpy(corruption_names=['shot_noise']):\n",
        "    x_clean, y_clean = load_cifar10(n_examples=10000, data_dir='../data')\n",
        "    x_corrs = []\n",
        "    y_corrs = []\n",
        "    x_corrs.append(x_clean)\n",
        "    y_corrs.append(y_clean)\n",
        "    for i in range(1, 6):\n",
        "        x_corr = []\n",
        "        y_corr = []\n",
        "        for j, corr in enumerate(corruptions):\n",
        "            x_, y_ = load_cifar10c(n_examples=10000, data_dir='../data', severity=i, corruptions=(corr,))\n",
        "            x_corr.append(x_)\n",
        "            y_corr.append(y_)\n",
        "\n",
        "        x_corrs.append(x_corr)\n",
        "        y_corrs.append(y_corr)\n",
        "\n",
        "    x_corrs_fast = []\n",
        "    y_corrs_fast = []\n",
        "    for i in range(1, 6):\n",
        "        x_, y_ = load_cifar10c(n_examples=1000, data_dir='../data', severity=i, shuffle=True)\n",
        "        x_corrs_fast.append(x_)\n",
        "        y_corrs_fast.append(y_)\n",
        "\n",
        "    return x_corrs, y_corrs, x_corrs_fast, y_corrs_fast\n",
        "\n",
        "\n",
        "datasets_dict = {'mnist': datasets.MNIST, 'mnist_binary': datasets.MNIST, 'svhn': datasets.SVHN, 'cifar10': datasets.CIFAR10,\n",
        "                 'cifar10_binary': datasets.CIFAR10, 'cifar10_binary_gs': datasets.CIFAR10, 'imagenet100': ImageNet100,\n",
        "                 'SIN': ImageNet100\n",
        "                 }\n",
        "shapes_dict = {'mnist': (60000, 1, 28, 28), 'mnist_binary': (13007, 1, 28, 28), 'svhn': (73257, 3, 32, 32),\n",
        "               'cifar10': (50000, 3, 32, 32), 'cifar10_binary': (10000, 3, 32, 32),\n",
        "               'cifar10_binary_gs': (10000, 1, 32, 32), 'uniform_noise': (1000, 1, 28, 28), 'imagenet100': (10000,3,224,224)\n",
        "               }\n",
        "classes_dict = {'cifar10': {0: 'airplane',\n",
        "                            1: 'automobile',\n",
        "                            2: 'bird',\n",
        "                            3: 'cat',\n",
        "                            4: 'deer',\n",
        "                            5: 'dog',\n",
        "                            6: 'frog',\n",
        "                            7: 'horse',\n",
        "                            8: 'ship',\n",
        "                            9: 'truck',\n",
        "                            }\n",
        "                }\n",
        "corruptions = ['shot_noise', 'motion_blur', 'snow', 'pixelate', 'gaussian_noise', 'defocus_blur',\n",
        "               'brightness', 'fog', 'zoom_blur', 'frost', 'glass_blur', 'impulse_noise', 'contrast',\n",
        "               'jpeg_compression', 'elastic_transform']\n",
        "\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "AEiuUpIysaPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H4cXX83LscxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FCVBjxDtD8dB"
      }
    }
  ]
}